import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
import matplotlib.pyplot as plt
from PIL import Image

# Load your handwritten X and non-X images for training
X_images = []
non_X_images = []
for i in range(1, 12):
    image_path = f"X_image_{i}.jpg"  # Update with your actual file names for X images
    img = Image.open(image_path).convert('L')  # Convert to grayscale, L means luminance
    img = img.resize((15, 15))  # Increase the image resolution
    X_images.append(np.array(img))

for i in range(1, 12):
    image_path = f"non_X_image_{i}.jpg"  # Update with your actual file names for non-X images
    img = Image.open(image_path).convert('L')  # Convert to grayscale
    img = img.resize((15, 15))  # Increase the image resolution
    non_X_images.append(np.array(img))

# Labels: X -> 1, non-X -> 0
labels = np.concatenate([np.ones(len(X_images)), np.zeros(len(non_X_images))])
images = np.array(X_images + non_X_images)

# Shuffle the dataset
indices = np.arange(len(images))
np.random.shuffle(indices)
labels = labels[indices]
images = images[indices]

# Define the model
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(15, 15, 1)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
#    layers.Dense(2, activation='sigmoid')  # Output layer with 2 neurons for binary classification
    layers.Dense(2, activation='softmax')  # Output layer with 2 neurons for binary classification
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])


# Train the model with your data
model.fit(images, labels, epochs=10, batch_size=4)

# Load the new test images
new_test_images = []
for i in range(1, 5):  # Update the range to include all four new test images
    image_path = f"new_test_image_{i}.jpg"  # Update with your actual file names for new test images
    img = Image.open(image_path).convert('L')  # Convert to grayscale
    img = img.resize((15, 15))  # Increase the image resolution
    new_test_images.append(np.array(img))

# Predict whether the new test images are X or non-X letters
new_test_images = np.array(new_test_images)
new_test_images = np.expand_dims(new_test_images, axis=-1)
predictions = model.predict(new_test_images)

# Evaluate the model on the new test data
true_labels = np.array([1, 1, 0, 0])  # Actual labels for the new test images (assuming first two are X, last two are non-X)
loss, accuracy = model.evaluate(new_test_images, true_labels)
print(f"Loss: {loss}, Accuracy: {accuracy}")

# Getting probabilistic values
probabilities = model.predict(new_test_images)

# Get the flattened layer values
flattened_output = model.layers[-3].output
flattened_model = tf.keras.Model(inputs=model.input, outputs=flattened_output)
flattened_features = flattened_model.predict(new_test_images)

print("Flattened Layer Values:", flattened_features.round(3))
print("Probabilistic Values:", probabilities.round(5))

# Display the new test images with predictions
plt.figure(figsize=(10, 5))
for i in range(len(new_test_images)):
    plt.subplot(1, 4, i + 1)
    plt.imshow(new_test_images[i].squeeze(), cmap='gray')  # Show grayscale images
    predicted_class = "X" if np.argmax(predictions[i]) == 1 else "Non-X"
    plt.title(f"Predicted: {predicted_class}")
    plt.axis('off')
plt.show()

# Train the model with validation split
history = model.fit(images, labels, epochs=50, batch_size=4, validation_split=0.3)

# Plot training & validation loss values
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

# Plot training & validation accuracy values
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

# Plot training & validation loss values
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

