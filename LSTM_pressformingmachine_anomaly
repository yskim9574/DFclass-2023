import	pandas	as	pd
import	numpy	as	np
import	matplotlib.pyplot	as	plt
from	tensorflow.keras.callbacks	import	EarlyStopping,	ReduceLROnPlateau
import	seaborn	as	sns
import	tensorflow	as	tf
from	tensorflow.keras	import	Model	,models,	layers,	optimizers,	regularizers
from	sklearn.preprocessing	import	MinMaxScaler
from	sklearn	import	metrics
from	sklearn.model_selection	import	train_test_split

# Load dataset into normal_data and anomaly_data
normal = pd.read_csv('press_data_normal.csv',	index_col=0)
outlier = pd.read_csv('press_data_outlier.csv',	index_col=0)
normal_data	=	normal.copy() 
outlier_data	=	outlier.copy()

#print(normal.head())
#print(outlier.head())
#normal.describe().T
#outlier.describe().T
#normal.isnull().sum()
#outlier.isnull().sum()

print('No. Normal	Data		:	{}'.format(len(normal_data))) 
print('No. Outlier	Data		:	{}'.format(len(outlier_data)))

use_col	=	['AI0_Vibration',	'AI1_Vibration',	'AI2_Current']
plt.figure(figsize=(30,15))
for	i	in	range(len(use_col)):
 plt.subplot(3,	1,	i+1)
 plt.title(use_col[i],	fontsize=30)
 plt.plot(normal_data[use_col[i]])
 plt.xticks(size=20)
 plt.yticks(size=20)
plt.tight_layout()

use_col	=	['AI0_Vibration',	'AI1_Vibration',	'AI2_Current']
plt.figure(figsize=(30,15))
for	i	in	range(len(use_col)):
 plt.subplot(3,	1,	i+1)
 plt.title(use_col[i],	fontsize=30)
 plt.plot(outlier_data[use_col[i]])
 plt.xticks(size=20)
 plt.yticks(size=20)
plt.tight_layout()

# Take the absolute value of normal/abnormal vibration data and convert it to amplitude
normal_data[use_col]	=	normal_data[use_col].applymap(lambda	x:	abs(x))	
outlier_data[use_col]	=	outlier_data[use_col].applymap(lambda	x:	abs(x))

normal_data[use_col].corr()
outlier_data[use_col].corr()

#	Normal/abnormal data preparation
X_normal	=	normal_data[use_col]
y_normal	=	normal_data['Equipment_state']	
X_anomaly	=	outlier_data[use_col]	
y_anomaly	=	outlier_data['Equipment_state']

#	Separate training and evaluation data
X_train_normal	=	X_normal[:15000] 
y_train_normal	=	y_normal[:15000]	
X_test_normal	=	X_normal[15000:]	
y_test_normal	=	y_normal[15000:]	
X_test_anomaly	=	X_anomaly	
y_test_anomaly	=	y_anomaly


#normalization
scaler	=	MinMaxScaler()
X_train_scaled	=	scaler.fit_transform(X_train_normal)	
X_test_normal_scaled	=	scaler.transform(X_test_normal)	
X_test_anomaly_scaled	=	scaler.transform(X_test_anomaly)
y_train_normal	=	np.array(y_train_normal)	
y_test_normal	=	np.array(y_test_normal)	
y_test_anomaly	=	np.array(y_test_anomaly)

#	Structural changes for LSTM training
sequence	=	20
X_train,	Y_train	=	[],	[]
for	index	in	range(len(X_train_scaled)	-	sequence- 100):
  X_train.append(X_train_scaled[index:	index	+	sequence])
  Y_train.append(y_train_normal[index	+	sequence	+	100])

#Normal data for evaluation
X_test_normal,	Y_test_normal	=	[],	[]
for	index	in	range(len(X_test_normal_scaled)	-	sequence-			 100):
  X_test_normal.append(X_test_normal_scaled[index:	index	+	sequence])
  Y_test_normal.append(y_test_normal[index	+	sequence	+	100])

#anomaly data for evaluation
X_test_anomal,	Y_test_anomal	=	[],	[]
for	index	in	range(len(X_test_anomaly_scaled)	-	sequence-	100):
  X_test_anomal.append(X_test_anomaly_scaled[index:	index	+	sequence])
  Y_test_anomal.append(y_test_anomaly[index	+	sequence	+	100])

#Convert list format to numpy array
X_test_normal,	Y_test_normal	=	np.array(X_test_normal),	np.array(Y_test_normal)
X_test_anomal,	Y_test_anomal	=	np.array(X_test_anomal),	np.array(Y_test_anomal)

#	Validation set configuration for LSTM-AE Threshold designation
X_valid_normal,	Y_valid_normal	=	X_test_normal[:880,	:,	:],	Y_test_normal[:880]
X_test_normal,	Y_test_normal	=	X_test_normal[880:,	:,	:],	Y_test_normal[880:]
X_valid_anomal,	Y_valid_anomal	=	X_test_anomal[:300,	:,	:],	Y_test_anomal[:300]
X_test_anomal,	Y_test_anomal	=	X_test_anomal[300:,	:,	:],	Y_test_anomal[300:]
X_valid	=	np.vstack((X_valid_normal,	X_valid_anomal))
Y_valid	=	np.hstack((Y_valid_normal,	Y_valid_anomal))
X_test	=	np.vstack((X_test_normal,	X_test_anomal))
Y_test	=	np.hstack((Y_test_normal,	Y_test_anomal))

#	Check dataset composition for learning, verification and evaluation
X_train,	Y_train	=	np.array(X_train),	np.array(Y_train)
X_valid,	Y_valid	=	np.array(X_valid),	np.array(Y_valid)
X_test,	Y_test	=	np.array(X_test),	np.array(Y_test)
print('X_train:',	X_train.shape,	'Y_train:',	Y_train.shape)
print('X_valid:',	X_valid.shape,	'Y_valid:',	Y_valid.shape)
print('X_test:',	X_test.shape,	'Y_test:',	Y_test.shape)

#	Separate only normal data from verification data
X_valid_0	=	X_valid[Y_valid==0]
X_valid_0.shape

#	Define and create LSTM-Autoencoder model
def	LSTM_AE(sequence,	n_features):
  lstm_ae	=	models.Sequential()

#	Encoder
  lstm_ae.add(layers.LSTM(64,	input_shape=(sequence,	n_features),	return_sequences=True))
  lstm_ae.add(layers.LSTM(32,	return_sequences=False))
  lstm_ae.add(layers.RepeatVector(sequence))
#	Decoder
  lstm_ae.add(layers.LSTM(32,	return_sequences=True))
  lstm_ae.add(layers.LSTM(64,	return_sequences=True))
  lstm_ae.add(layers.TimeDistributed(layers.Dense(n_features)))
  return	lstm_ae

lstm_ae	=	LSTM_AE(20,	3)
lstm_ae.summary()

#Callbacks declaration during model learning process
reduce_lr	=	ReduceLROnPlateau(monitor='val_loss',	factor=0.7,	patience=50,	verbose=1)
es	=	EarlyStopping(monitor='val_loss',	min_delta=0.00001,	patience=120,	verbose=1,	mode='min',
restore_best_weights=True)

#Model compilation and training progress
lstm_ae.compile(loss='mse',	optimizer=optimizers.Adam(0.001))

#	fit
history	=	lstm_ae.fit(X_train,	X_train,
epochs=600,	batch_size=128,
callbacks=[reduce_lr,	es],	validation_data=(X_valid_0,	X_valid_0))


# Plot the loss-epoch curve for train-loss and valid-loss
plt.plot(history.history['loss'],	label='train	loss')
plt.plot(history.history['val_loss'],	label='valid	loss')
plt.legend()
plt.xlabel('Epoch');	plt.ylabel('loss')
plt.show()

#A function that reduces the data dimension to calculate the reconstruction error of model output and input values. 
flattened = []  # Initialize flattened as an empty list before using it in the function
def flatten(X):
  for i in range(X.shape[0]):
    flattened[i] = X[i, X.shape[1]-1, :]
  return flattened

#	Specify LSTM-Autoencoder threshold and visualize precision and recall curves based on threshold
valid_x_predictions	=	lstm_ae.predict(X_valid)
mse	=	np.mean(np.power(flatten(X_valid)	-	flatten(valid_x_predictions),	2),	axis=1) 
precision,	recall,	threshold	=	metrics.precision_recall_curve(list(Y_valid),	mse)	
index_cnt	=	[cnt	for	cnt,	(p,	r)	in	enumerate(zip(precision,	recall))	if	p==r][0]	
threshold_final	=	threshold[index_cnt]

plt.figure(figsize=(10,7))
plt.title("Precision/Recall	Curve	for	threshold",	fontsize=15)	
plt.plot(threshold[threshold	<=	0.2],	precision[1:][threshold	<=	0.2],	label="Precision")	
plt.plot(threshold[threshold	<=	0.2],	recall[1:][threshold	<=	0.2],	label="Recall")	
plt.plot(threshold_final,	precision[index_cnt],	"o",	color="r",	label="Optimal	threshold")	
plt.xlabel("Threshold")
plt.ylabel("Precision/Recall")
plt.legend()
plt.show()
print("precision:	",precision[index_cnt],",	recall:	",recall[index_cnt])	
print("threshold:	",threshold_final)

# Confusion matrix visualization
pred_y	=	[1	if	e	>	threshold_final	else	0	for	e	in	mse]
conf_matrix	=	metrics.confusion_matrix(list(Y_test),	pred_y)	
plt.figure(figsize=(7,	7))
sns.heatmap(conf_matrix,	xticklabels=[0,1],	yticklabels=[0,1],	annot=True,	fmt='d')	
plt.title('Confusion	Matrix')
plt.xlabel('Predicted	Class')
plt.ylabel('True	Class')	
plt.show()

#	LSTM-Autoencoder accuracy output
print('Accuracy	:	{}'.format(metrics.accuracy_score(list(Y_test),	pred_y)))
#	LSTM-Autoencoder	F1 output
print('F1-Score	:	{}'.format(metrics.f1_score(list(Y_test),	pred_y)))
